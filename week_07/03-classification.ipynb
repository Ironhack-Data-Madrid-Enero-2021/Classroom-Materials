{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-exploration\" data-toc-modified-id=\"Data-exploration-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data exploration</a></span></li><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Logistic regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#1-predictor\" data-toc-modified-id=\"1-predictor-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>1 predictor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Accuracy-score\" data-toc-modified-id=\"Accuracy-score-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Accuracy score</a></span></li></ul></li><li><span><a href=\"#Many-predictors\" data-toc-modified-id=\"Many-predictors-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Many predictors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Accuracy-score\" data-toc-modified-id=\"Accuracy-score-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Accuracy score</a></span></li><li><span><a href=\"#predict_proba\" data-toc-modified-id=\"predict_proba-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span><code>predict_proba</code></a></span></li><li><span><a href=\"#Setting-threshold-manually\" data-toc-modified-id=\"Setting-threshold-manually-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Setting threshold manually</a></span></li></ul></li></ul></li><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Accuracy</a></span></li><li><span><a href=\"#Recall\" data-toc-modified-id=\"Recall-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Recall</a></span></li><li><span><a href=\"#Precision\" data-toc-modified-id=\"Precision-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Precision</a></span></li><li><span><a href=\"#F1-score\" data-toc-modified-id=\"F1-score-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>F1 score</a></span></li><li><span><a href=\"#F_beta-score\" data-toc-modified-id=\"F_beta-score-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>F_beta score</a></span></li></ul></li><li><span><a href=\"#Choosing-the-best-threshold\" data-toc-modified-id=\"Choosing-the-best-threshold-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Choosing the best threshold</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an introductory notebook, I am not using train and test split for metric evaluation  \n",
    "But you should always do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Regression models are used when the target variable is **quantitative**: \n",
    "  - salaries\n",
    "  - gas emissions\n",
    "  - age of person in a picture\n",
    "  - ...\n",
    " * **Classification** models are used when the target variable is **qualitative**: \n",
    "  - surviving (or not) the Titanic\n",
    "  - paying back (or not) a loan\n",
    "  - identifying a dog (or not) in a picture\n",
    "  - deciding which one of 3 plant species is this one\n",
    "  - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics are specially important in classification problems!\n",
    "\n",
    "You must understand the business goal in order to choose the appropiate metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation:  \n",
    "a) radius (mean of distances from center to points on the perimeter)  \n",
    "b) texture (standard deviation of gray-scale values)  \n",
    "c) perimeter  \n",
    "d) area  \n",
    "e) smoothness (local variation in radius lengths)  \n",
    "f) compactness (perimeter^2 / area - 1.0)  \n",
    "g) concavity (severity of concave portions of the contour)  \n",
    "h) concave points (number of concave portions of the contour)  \n",
    "i) symmetry  \n",
    "j) fractal dimension (\"coastline approximation\" - 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable is `is_cancer`  \n",
    "It is a categorical variable, taking possible values $0$ and $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_cancer.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df.is_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression:\n",
    " * is the most frequently used classification algorithm\n",
    " * (binary classification) predicts a **probability** $p$ for class $1$ (`True`), and $1-p$ for class $0$ (`False`) \n",
    " * (multi classification) predicts a **probability** for every class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to predict `is_cancer` using only as a predictor `mean_radius`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df.mean_radius, y=df.is_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[\"mean_radius\", \"is_cancer\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sample(10).sort_values(\"mean_radius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(\n",
    "    X=df2[[\"mean_radius\"]],\n",
    "    y=df2.is_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"prediction_cancer\"] = log.predict(df2[[\"mean_radius\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many predictions were correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"correct\"] = (df2.is_cancer == df2.prediction_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is the proportion of good predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = df2.correct.sum() / df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many True/False Positives/Negatives do we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/andrewwlong/classification_metrics_sklearn/raw/541a0d065ffb8b3ff705161f6d16088d434b2ea7/img/conf_matrix.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    df2.is_cancer,\n",
    "    df2.prediction_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(\n",
    "    y_true=df2.is_cancer,\n",
    "    y_pred=df2.prediction_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphical interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(df.mean_radius.min(), df.mean_radius.max(), 100)\n",
    "y = log.predict(x.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df.mean_radius, y=df.is_cancer)\n",
    "plt.plot(x, y, c= \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use all variables **but** `is_cancer` to try and predict `is_cancer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df3.drop(\"is_cancer\", axis=1)\n",
    "y=df3.is_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"prediction_cancer\"] = log.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b = df3[[\"is_cancer\", \"prediction_cancer\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b[\"correct\"] = (df3b.is_cancer == df3.prediction_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/andrewwlong/classification_metrics_sklearn/raw/541a0d065ffb8b3ff705161f6d16088d434b2ea7/img/conf_matrix.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    df3b.is_cancer,\n",
    "    df3b.prediction_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is the proportion of good predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = df3b.correct.sum() / df3b.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got better accuracy using many predictors instead of one (as expected!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `predict_proba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression actually predicts probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We, as data scientists, want more precise information than just the *discrete* prediction 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.predict(X)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.predict_proba(X)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"prediction_proba_cancer\"] = log.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b[\"prediction_proba_cancer\"] = df3.prediction_proba_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphical interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(df.mean_radius.min()-5, df.mean_radius.max() + 5, 100)\n",
    "y = log.predict_proba(x.reshape(-1, 1))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(x=df.mean_radius, y=df.is_cancer)\n",
    "plt.plot(x, y, c= \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting threshold manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default `predict` just computes `predict_proba` > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the original confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    df3b.is_cancer,\n",
    "    df3b.prediction_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets change the default threshold 0.5 and see how results change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the threshold as 0.1 *invites* predictions to be Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will False Positives increase?  \n",
    "Will False Negatives increase?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1: low threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    df3b.is_cancer,\n",
    "    df3b.prediction_proba_cancer > threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all positives were found (higher **recall**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More false positives appeared (lower **precision**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2: high threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    df3b.is_cancer,\n",
    "    df3b.prediction_proba_cancer > threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all predicted positives are true (higher **precision**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predicted 28 real cancers as False (low **recall**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: \n",
    " * a metric should be chosen a-priori, with deep understanding of the problem. Then several models are trained and the one with best metric result is chosen\n",
    " * here we present different metrics for the same model as an exercise. The results (0.94, 0.92, 0.95 should by no means be compared!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left rectangle, Real Positives  \n",
    "On the right rectangle, Real Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the circle, Predicted Positives  \n",
    "Outside the circle, Predicted Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/andrewwlong/classification_metrics_sklearn/raw/541a0d065ffb8b3ff705161f6d16088d434b2ea7/img/buckets.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/andrewwlong/classification_metrics_sklearn/raw/541a0d065ffb8b3ff705161f6d16088d434b2ea7/img/conf_matrix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * It represents the proportion of samples predicted correctly\n",
    " * The most common metric for classification\n",
    " * Useful when:\n",
    "  - dataset has balanced classes (similar proportion of True and False)\n",
    "  - there is symmetry between True and False (for example, predicting \"male\" or \"female\")\n",
    " * **Often misused!!** since:\n",
    "  - many problems are not symmetric (for example, cancer vs no cancer)\n",
    "  - many problems have imbalanced classes (for example, terrorist vs no terrorist)\n",
    " * I do not like accuracy metric. Be alert!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/andrewwlong/classification_metrics_sklearn/raw/541a0d065ffb8b3ff705161f6d16088d434b2ea7/img/accuracy.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(\n",
    "    y_true=df3b.is_cancer,\n",
    "    y_pred=df3b.prediction_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(also known as sensitivity) is the fraction of positive events that you predicted correctly as shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It values as **crucial** to identify true instances (useful for cancer detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/andrewwlong/classification_metrics_sklearn/raw/541a0d065ffb8b3ff705161f6d16088d434b2ea7/img/recall.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(\n",
    "    y_true=df3b.is_cancer,\n",
    "    y_pred=df3b.prediction_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is the fraction of predicted positives events that are actually positive as shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It values as **crucial** to **not** have False Positives (very aggresive treatments of not very malicious diseases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/andrewwlong/classification_metrics_sklearn/raw/541a0d065ffb8b3ff705161f6d16088d434b2ea7/img/precision.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(\n",
    "    y_true=df3b.is_cancer,\n",
    "    y_pred=df3b.prediction_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **recall** is, in general, more important than precision but...\n",
    " * higher recall always implies lower precision\n",
    " * a tradeoff should be found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score is the harmonic mean of recall and precision:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/andrewwlong/classification_metrics_sklearn/raw/541a0d065ffb8b3ff705161f6d16088d434b2ea7/img/f1_score.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    y_true=df3b.is_cancer,\n",
    "    y_pred=df3b.prediction_cancer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F_beta score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **recall** is, in general, more important than precision but...\n",
    " * higher recall always implies lower precision\n",
    " * a tradeoff should be found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $F_1$ score is the harmonic mean of recall and precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $F_\\beta$ score is a weighed harmonic mean of recall and precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `beta` parameter determines the weight of **recall** in the combined score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We, toguether with doctors (technicians) and government (money, time) decide that $\\beta=3$ is a good choice for breast cancer detection:\n",
    " * we value finding real positives...\n",
    " * 3 times more than...\n",
    " * losing time with false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta_score(\n",
    "    y_true=df3b.is_cancer,\n",
    "    y_pred=df3b.prediction_cancer,\n",
    "    beta=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets choose the threshold that optimizes $F_3$ score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df3b.is_cancer\n",
    "\n",
    "for threshold in np.arange(0, 1, 0.05):\n",
    "    y_pred = df3b.prediction_proba_cancer > threshold\n",
    "    \n",
    "    result = {\n",
    "        \"threshold\": threshold,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f3\": fbeta_score(y_true, y_pred, beta=3)\n",
    "    }\n",
    "    \n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(results)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold = res.threshold[res.f3.argmax()]\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/andrewwlong/classification_metrics_sklearn/raw/541a0d065ffb8b3ff705161f6d16088d434b2ea7/img/conf_matrix.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df3b.is_cancer, df3b.prediction_proba_cancer > optimal_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Classification predicts qualitative outputs (classes)\n",
    " * Logistic regression is the most commonly used classification algorithm\n",
    " * Logistic regression predicts probabilities (`.predict_proba`, between 0 and 1) and may apply threshold for you (`.predict`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * We have different classification metrics\n",
    " * A metric should be decided before training different models! Human criteria translates to metric choice\n",
    " * A metric lets us choose the best model (here we chose the best threshold for our final model)\n",
    " * For choosing a metric, look at \n",
    "  - class balance\n",
    "  - class symmetry"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "supervised-learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
