{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Web Scraping Lab\n",
    "\n",
    "In this lab you will first learn the following code snippet which is a simple web spider class that allows you to scrape paginated webpages. Read the code, run it, and make sure you understand how it work. In the challenges of this lab, we will guide you in building up this class so that eventually you will have a more robus web spider that you can further work on in the Web Scraping Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n\\t<meta charset=\"UTF-8\">\\n\\t<title>Quotes to Scrape</title>\\n    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\\n    <link rel=\"stylesheet\" href=\"/static/main.css\">\\n</head>\\n<body>\\n    <div class=\"container\">\\n        <div class=\"row header-box\">\\n            <div class=\"col-md-8\">\\n                <h1>\\n                    <a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\\n                </h1>\\n            </div>\\n            <div class=\"col-md-4\">\\n                <p>\\n                \\n                    <a href=\"/login\">Login</a>\\n                \\n                </p>\\n            </div>\\n        </div>\\n    \\n\\n<div class=\"row\">\\n    <div class=\"col-md-8\">\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\\n        <a href=\"/author/Albert-Einstein\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"change,deep-thoughts,thinking,world\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\\n            \\n            <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\\n            \\n            <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\\n            \\n            <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cIt is our choices, Harry, that show what we truly are, far more than our abilities.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">J.K. Rowling</small>\\n        <a href=\"/author/J-K-Rowling\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"abilities,choices\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/abilities/page/1/\">abilities</a>\\n            \\n            <a class=\"tag\" href=\"/tag/choices/page/1/\">choices</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\\n        <a href=\"/author/Albert-Einstein\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"inspirational,life,live,miracle,miracles\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\\n            \\n            <a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\\n            \\n            <a class=\"tag\" href=\"/tag/live/page/1/\">live</a>\\n            \\n            <a class=\"tag\" href=\"/tag/miracle/page/1/\">miracle</a>\\n            \\n            <a class=\"tag\" href=\"/tag/miracles/page/1/\">miracles</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Jane Austen</small>\\n        <a href=\"/author/Jane-Austen\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"aliteracy,books,classic,humor\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/aliteracy/page/1/\">aliteracy</a>\\n            \\n            <a class=\"tag\" href=\"/tag/books/page/1/\">books</a>\\n            \\n            <a class=\"tag\" href=\"/tag/classic/page/1/\">classic</a>\\n            \\n            <a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cImperfection is beauty, madness is genius and it&#39;s better to be absolutely ridiculous than absolutely boring.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Marilyn Monroe</small>\\n        <a href=\"/author/Marilyn-Monroe\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"be-yourself,inspirational\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/be-yourself/page/1/\">be-yourself</a>\\n            \\n            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cTry not to become a man of success. Rather become a man of value.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\\n        <a href=\"/author/Albert-Einstein\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"adulthood,success,value\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/adulthood/page/1/\">adulthood</a>\\n            \\n            <a class=\"tag\" href=\"/tag/success/page/1/\">success</a>\\n            \\n            <a class=\"tag\" href=\"/tag/value/page/1/\">value</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cIt is better to be hated for what you are than to be loved for what you are not.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Andr\\xc3\\xa9 Gide</small>\\n        <a href=\"/author/Andre-Gide\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"life,love\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\\n            \\n            <a class=\"tag\" href=\"/tag/love/page/1/\">love</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cI have not failed. I&#39;ve just found 10,000 ways that won&#39;t work.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Thomas A. Edison</small>\\n        <a href=\"/author/Thomas-A-Edison\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"edison,failure,inspirational,paraphrased\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/edison/page/1/\">edison</a>\\n            \\n            <a class=\"tag\" href=\"/tag/failure/page/1/\">failure</a>\\n            \\n            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\\n            \\n            <a class=\"tag\" href=\"/tag/paraphrased/page/1/\">paraphrased</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cA woman is like a tea bag; you never know how strong it is until it&#39;s in hot water.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Eleanor Roosevelt</small>\\n        <a href=\"/author/Eleanor-Roosevelt\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"misattributed-eleanor-roosevelt\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/misattributed-eleanor-roosevelt/page/1/\">misattributed-eleanor-roosevelt</a>\\n            \\n        </div>\\n    </div>\\n\\n    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\\n        <span class=\"text\" itemprop=\"text\">\\xe2\\x80\\x9cA day without sunshine is like, you know, night.\\xe2\\x80\\x9d</span>\\n        <span>by <small class=\"author\" itemprop=\"author\">Steve Martin</small>\\n        <a href=\"/author/Steve-Martin\">(about)</a>\\n        </span>\\n        <div class=\"tags\">\\n            Tags:\\n            <meta class=\"keywords\" itemprop=\"keywords\" content=\"humor,obvious,simile\" /    > \\n            \\n            <a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\\n            \\n            <a class=\"tag\" href=\"/tag/obvious/page/1/\">obvious</a>\\n            \\n            <a class=\"tag\" href=\"/tag/simile/page/1/\">simile</a>\\n            \\n        </div>\\n    </div>\\n\\n    <nav>\\n        <ul class=\"pager\">\\n            \\n            \\n            <li class=\"next\">\\n                <a href=\"/page/2/\">Next <span aria-hidden=\"true\">&rarr;</span></a>\\n            </li>\\n            \\n        </ul>\\n    </nav>\\n    </div>\\n    <div class=\"col-md-4 tags-box\">\\n        \\n            <h2>Top Ten tags</h2>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 28px\" href=\"/tag/love/\">love</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 26px\" href=\"/tag/inspirational/\">inspirational</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 26px\" href=\"/tag/life/\">life</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 24px\" href=\"/tag/humor/\">humor</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 22px\" href=\"/tag/books/\">books</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 14px\" href=\"/tag/reading/\">reading</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 10px\" href=\"/tag/friendship/\">friendship</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 8px\" href=\"/tag/friends/\">friends</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 8px\" href=\"/tag/truth/\">truth</a>\\n            </span>\\n            \\n            <span class=\"tag-item\">\\n            <a class=\"tag\" style=\"font-size: 6px\" href=\"/tag/simile/\">simile</a>\\n            </span>\\n            \\n        \\n    </div>\\n</div>\\n\\n    </div>\\n    <footer class=\"footer\">\\n        <div class=\"container\">\\n            <p class=\"text-muted\">\\n                Quotes by: <a href=\"https://www.goodreads.com/quotes\">GoodReads.com</a>\\n            </p>\\n            <p class=\"copyright\">\\n                Made with <span class=\\'sh-red\\'>\\xe2\\x9d\\xa4</span> by <a href=\"https://scrapinghub.com\">Scrapinghub</a>\\n            </p>\\n        </div>\\n    </footer>\\n</body>\\n</html>'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    return content\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1 - Custom Parser Function\n",
    "\n",
    "In this challenge, complete the custom `quotes_parser()` function so that the returned result contains the quote string instead of the whole html page content.\n",
    "\n",
    "In the cell below, write your updated `quotes_parser()` function and kickstart the spider. Make sure the results being printed contain a list of quote strings extracted from the html content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#def quotes_parser(content):\n",
    "#    soup_contenido = BeautifulSoup(content, \"html.parser\")\n",
    "#    quotes = soup_contenido.find_all('span', class_='text')\n",
    "#    entre_comillas = []\n",
    "#    for frase in quotes:\n",
    "#        entre_comillas.append(frase.text)\n",
    "#    return entre_comillas\n",
    "\n",
    "def quotes_parser(content):\n",
    "    soup_contenido = BeautifulSoup(content, \"html.parser\")\n",
    "    quotes = [frase.text for frase in soup_contenido.find_all('span', class_='text')]\n",
    "    \n",
    "    return quotes\n",
    "      \n",
    "\n",
    "\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2 - Error Handling\n",
    "\n",
    "In `IronhackSpider.scrape_url()`, catch any error that might occur when you make requests to scrape the webpage. This includes checking the response status code and catching http request errors such as timeout, SSL, and too many redirects.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            result = self.content_parser(response.content)    \n",
    "        except requests.exceptions.HTTPError as e_http:\n",
    "            result = \"Error http:\" + str(e_http)\n",
    "        except requests.exceptions.ConnectionError as e_conect:\n",
    "            result = \"Error de conexión:\" + str(e_conect)\n",
    "        except requests.exceptions.SSLError as e_ssl:\n",
    "            result = \"Error de SSL: \" + str(e_ssl)\n",
    "        except requests.exceptions.Timeout as e_time:\n",
    "            result = \"Error timeout:\" + str(e_time)\n",
    "        except requests.exceptions.TooManyRedirects as e_redi:\n",
    "            result = \"Error demasiadas redirecciones:\" + str(e_redi)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            result = \"Error Desconocido: \" + str(e)\n",
    "        \n",
    "        self.output_results(result)   \n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup_contenido = BeautifulSoup(content, \"html.parser\")\n",
    "    quotes = [frase.text for frase in soup_contenido.find_all('span', class_='text')]\n",
    "    \n",
    "    return quotes\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Sleep Interval\n",
    "\n",
    "In `IronhackSpider.kickstart()`, implement `sleep_interval`. You will check if `self.sleep_interval` is larger than 0. If so, tell the FOR loop to sleep the given amount of time before making the next request.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import time\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            result = self.content_parser(response.content)    \n",
    "        except requests.exceptions.HTTPError as e_http:\n",
    "            result = \"Error http:\" + str(e_http)\n",
    "        except requests.exceptions.ConnectionError as e_conect:\n",
    "            result = \"Error de conexión:\" + str(e_conect)\n",
    "        except requests.exceptions.SSLError as e_ssl:\n",
    "            result = \"Error de SSL: \" + str(e_ssl)\n",
    "        except requests.exceptions.Timeout as e_time:\n",
    "            result = \"Error timeout:\" + str(e_time)\n",
    "        except requests.exceptions.TooManyRedirects as e_redi:\n",
    "            result = \"Error demasiadas redirecciones:\" + str(e_redi)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            result = \"Error Desconocido: \" + str(e)\n",
    "        \n",
    "        self.output_results(result)   \n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "            if self.sleep_interval > 0: \n",
    "                time.sleep(5 / 1000)\n",
    "\n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup_contenido = BeautifulSoup(content, \"html.parser\")\n",
    "    quotes = [frase.text for frase in soup_contenido.find_all('span', class_='text')]\n",
    "    \n",
    "    return quotes\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Test Batch Scraping\n",
    "\n",
    "Change the `PAGES_TO_SCRAPE` value from `1` to `10`. Try if your code still works as intended to scrape 10 webpages. If there are errors in your code, fix them.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n",
      "[\"“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\", '“It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.”', \"“If you can't explain it to a six year old, you don't understand it yourself.”\", \"“You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect—you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break—her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.”\", '“I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.”', '“I may not have gone where I intended to go, but I think I have ended up where I needed to be.”', \"“The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.”\", '“It is not a lack of love, but a lack of friendship that makes unhappy marriages.”', '“Good friends, good books, and a sleepy conscience: this is the ideal life.”', '“Life is what happens to us while we are making other plans.”']\n",
      "['“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”', '“For every minute you are angry you lose sixty seconds of happiness.”', '“If you judge people, you have no time to love them.”', '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”', '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”', '“Today you are You, that is truer than true. There is no one alive who is Youer than You.”', '“If you want your children to be intelligent, read them fairy tales. If you want them to be more intelligent, read them more fairy tales.”', '“It is impossible to live without failing at something, unless you live so cautiously that you might as well not have lived at all - in which case, you fail by default.”', '“Logic will get you from A to Z; imagination will get you everywhere.”', '“One good thing about music, when it hits you, you feel no pain.”']\n",
      "[\"“The more that you read, the more things you will know. The more that you learn, the more places you'll go.”\", '“Of course it is happening inside your head, Harry, but why on earth should that mean that it is not real?”', '“The truth is, everyone is going to hurt you. You just got to find the ones worth suffering for.”', '“Not all of us can do great things. But we can do small things with great love.”', '“To the well-organized mind, death is but the next great adventure.”', \"“All you need is love. But a little chocolate now and then doesn't hurt.”\", \"“We read to know we're not alone.”\", '“Any fool can know. The point is to understand.”', '“I have always imagined that Paradise will be a kind of library.”', '“It is never too late to be what you might have been.”']\n",
      "['“A reader lives a thousand lives before he dies, said Jojen. The man who never reads lives only one.”', '“You can never get a cup of tea large enough or a book long enough to suit me.”', '“You believe lies so you eventually learn to trust no one but yourself.”', '“If you can make a woman laugh, you can make her do anything.”', '“Life is like riding a bicycle. To keep your balance, you must keep moving.”', '“The real lover is the man who can thrill you by kissing your forehead or smiling into your eyes or just staring into space.”', \"“A wise girl kisses but doesn't love, listens but doesn't believe, and leaves before she is left.”\", '“Only in the darkness can you see the stars.”', '“It matters not what someone is born, but what they grow to be.”', '“Love does not begin and end the way we seem to think it does. Love is a battle, love is a war; love is a growing up.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import time\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            result = self.content_parser(response.content)    \n",
    "        except requests.exceptions.HTTPError as e_http:\n",
    "            result = \"Error http:\" + str(e_http)\n",
    "        except requests.exceptions.ConnectionError as e_conect:\n",
    "            result = \"Error de conexión:\" + str(e_conect)\n",
    "        except requests.exceptions.SSLError as e_ssl:\n",
    "            result = \"Error de SSL: \" + str(e_ssl)\n",
    "        except requests.exceptions.Timeout as e_time:\n",
    "            result = \"Error timeout:\" + str(e_time)\n",
    "        except requests.exceptions.TooManyRedirects as e_redi:\n",
    "            result = \"Error demasiadas redirecciones:\" + str(e_redi)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            result = \"Error Desconocido: \" + str(e)\n",
    "        \n",
    "        self.output_results(result)   \n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "            if self.sleep_interval > 0: \n",
    "                time.sleep(5 / 1000)\n",
    "\n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 5 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup_contenido = BeautifulSoup(content, \"html.parser\")\n",
    "    quotes = [frase.text for frase in soup_contenido.find_all('span', class_='text')]\n",
    "    \n",
    "    return quotes\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "SET_INTERVAL = 5\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, SET_INTERVAL, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5 - Scrape a Different Website\n",
    "\n",
    "Update the parameters passed to the `IronhackSpider` constructor so that you coder can crawl [books.toscrape.com](http://books.toscrape.com/). You will need to use a different `URL_PATTERN` (figure out the new url pattern by yourself) and write another parser function to be passed to `IronhackSpider`. \n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A Light in the Attic', '£51.77'), ('Tipping the Velvet', '£53.74'), ('Soumission', '£50.10'), ('Sharp Objects', '£47.82'), ('Sapiens: A Brief History of Humankind', '£54.23'), ('The Requiem Red', '£22.65'), ('The Dirty Little Secrets of Getting Your Dream Job', '£33.34'), ('The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', '£17.93'), ('The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', '£22.60'), ('The Black Maria', '£52.15'), ('Starving Hearts (Triangular Trade Trilogy, #1)', '£13.99'), (\"Shakespeare's Sonnets\", '£20.66'), ('Set Me Free', '£17.46'), (\"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", '£52.29'), ('Rip it Up and Start Again', '£35.02'), ('Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991', '£57.25'), ('Olio', '£23.88'), ('Mesaerion: The Best Science Fiction Stories 1800-1849', '£37.59'), ('Libertarianism for Beginners', '£51.33'), (\"It's Only the Himalayas\", '£45.17')]\n",
      "[('In Her Wake', '£12.84'), ('How Music Works', '£37.32'), ('Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More', '£30.52'), ('Chase Me (Paris Nights #2)', '£25.27'), ('Black Dust', '£34.53'), ('Birdsong: A Story in Pictures', '£54.64'), (\"America's Cradle of Quarterbacks: Western Pennsylvania's Football Factory from Johnny Unitas to Joe Montana\", '£22.50'), ('Aladdin and His Wonderful Lamp', '£53.13'), ('Worlds Elsewhere: Journeys Around Shakespeare’s Globe', '£40.30'), ('Wall and Piece', '£44.18'), ('The Four Agreements: A Practical Guide to Personal Freedom', '£17.66'), ('The Five Love Languages: How to Express Heartfelt Commitment to Your Mate', '£31.05'), ('The Elephant Tree', '£23.82'), ('The Bear and the Piano', '£36.89'), (\"Sophie's World\", '£15.94'), ('Penny Maybe', '£33.29'), ('Maude (1883-1993):She Grew Up with the country', '£18.02'), ('In a Dark, Dark Wood', '£19.63'), ('Behind Closed Doors', '£52.22'), (\"You can't bury them all: Poems\", '£33.63')]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import time\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            result = self.content_parser(response.content)    \n",
    "        except requests.exceptions.HTTPError as e_http:\n",
    "            result = \"Error http:\" + str(e_http)\n",
    "        except requests.exceptions.ConnectionError as e_conect:\n",
    "            result = \"Error de conexión:\" + str(e_conect)\n",
    "        except requests.exceptions.SSLError as e_ssl:\n",
    "            result = \"Error de SSL: \" + str(e_ssl)\n",
    "        except requests.exceptions.Timeout as e_time:\n",
    "            result = \"Error timeout:\" + str(e_time)\n",
    "        except requests.exceptions.TooManyRedirects as e_redi:\n",
    "            result = \"Error demasiadas redirecciones:\" + str(e_redi)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            result = \"Error Desconocido: \" + str(e)\n",
    "        \n",
    "        self.output_results(result)   \n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "            if self.sleep_interval > 0: \n",
    "                time.sleep(self.sleep_interval / 1000)\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup_contenido = BeautifulSoup(content, \"html.parser\")\n",
    "    titulos = [titulo['alt'] for titulo in soup_contenido.find_all('img')]\n",
    "    precios = [precio.text for precio in soup_contenido.find_all('p', class_=\"price_color\")]\n",
    "    libros = [ (titulos[libro], precios[libro])  for libro in range(len(titulos))]\n",
    "    \n",
    "    return libros\n",
    "\n",
    "URL_PATTERN = 'http://books.toscrape.com/catalogue/page-%d.html'\n",
    "PAGES_TO_SCRAPE = 2\n",
    "SET_INTERVAL = 1\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, SET_INTERVAL, content_parser=quotes_parser)\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 1 - Making Your Spider Unblockable\n",
    "\n",
    "Use techniques such as randomizing user agents and referers in your requests to reduce the likelihood that your spider is blocked by websites. [Here](http://blog.adnansiddiqi.me/5-strategies-to-write-unblock-able-web-scrapers-in-python/) is a great article to learn these techniques.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A Light in the Attic', '£51.77'), ('Tipping the Velvet', '£53.74'), ('Soumission', '£50.10'), ('Sharp Objects', '£47.82'), ('Sapiens: A Brief History of Humankind', '£54.23'), ('The Requiem Red', '£22.65'), ('The Dirty Little Secrets of Getting Your Dream Job', '£33.34'), ('The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', '£17.93'), ('The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', '£22.60'), ('The Black Maria', '£52.15'), ('Starving Hearts (Triangular Trade Trilogy, #1)', '£13.99'), (\"Shakespeare's Sonnets\", '£20.66'), ('Set Me Free', '£17.46'), (\"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", '£52.29'), ('Rip it Up and Start Again', '£35.02'), ('Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991', '£57.25'), ('Olio', '£23.88'), ('Mesaerion: The Best Science Fiction Stories 1800-1849', '£37.59'), ('Libertarianism for Beginners', '£51.33'), (\"It's Only the Himalayas\", '£45.17')]\n",
      "[('In Her Wake', '£12.84'), ('How Music Works', '£37.32'), ('Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More', '£30.52'), ('Chase Me (Paris Nights #2)', '£25.27'), ('Black Dust', '£34.53'), ('Birdsong: A Story in Pictures', '£54.64'), (\"America's Cradle of Quarterbacks: Western Pennsylvania's Football Factory from Johnny Unitas to Joe Montana\", '£22.50'), ('Aladdin and His Wonderful Lamp', '£53.13'), ('Worlds Elsewhere: Journeys Around Shakespeare’s Globe', '£40.30'), ('Wall and Piece', '£44.18'), ('The Four Agreements: A Practical Guide to Personal Freedom', '£17.66'), ('The Five Love Languages: How to Express Heartfelt Commitment to Your Mate', '£31.05'), ('The Elephant Tree', '£23.82'), ('The Bear and the Piano', '£36.89'), (\"Sophie's World\", '£15.94'), ('Penny Maybe', '£33.29'), ('Maude (1883-1993):She Grew Up with the country', '£18.02'), ('In a Dark, Dark Wood', '£19.63'), ('Behind Closed Doors', '£52.22'), (\"You can't bury them all: Poems\", '£33.63')]\n",
      "[('Slow States of Collapse: Poems', '£57.31'), ('Reasons to Stay Alive', '£26.41'), ('Private Paris (Private #10)', '£47.61'), ('#HigherSelfie: Wake Up Your Life. Free Your Soul. Find Your Tribe.', '£23.11'), ('Without Borders (Wanderlove #1)', '£45.07'), ('When We Collided', '£31.77'), ('We Love You, Charlie Freeman', '£50.27'), ('Untitled Collection: Sabbath Poems 2014', '£14.27'), ('Unseen City: The Majesty of Pigeons, the Discreet Charm of Snails & Other Wonders of the Urban Wilderness', '£44.18'), ('Unicorn Tracks', '£18.78'), ('Unbound: How Eight Technologies Made Us Human, Transformed Society, and Brought Our World to the Brink', '£25.52'), ('Tsubasa: WoRLD CHRoNiCLE 2 (Tsubasa WoRLD CHRoNiCLE #2)', '£16.28'), ('Throwing Rocks at the Google Bus: How Growth Became the Enemy of Prosperity', '£31.12'), ('This One Summer', '£19.49'), ('Thirst', '£17.27'), ('The Torch Is Passed: A Harding Family Story', '£19.09'), ('The Secret of Dreadwillow Carse', '£56.13'), ('The Pioneer Woman Cooks: Dinnertime: Comfort Classics, Freezer Food, 16-Minute Meals, and Other Delicious Ways to Solve Supper!', '£56.41'), ('The Past Never Ends', '£56.50'), ('The Natural History of Us (The Fine Art of Pretending #2)', '£45.22')]\n",
      "[('The Nameless City (The Nameless City #1)', '£38.16'), ('The Murder That Never Was (Forensic Instincts #5)', '£54.11'), (\"The Most Perfect Thing: Inside (and Outside) a Bird's Egg\", '£42.96'), ('The Mindfulness and Acceptance Workbook for Anxiety: A Guide to Breaking Free from Anxiety, Phobias, and Worry Using Acceptance and Commitment Therapy', '£23.89'), ('The Life-Changing Magic of Tidying Up: The Japanese Art of Decluttering and Organizing', '£16.77'), ('The Inefficiency Assassin: Time Management Tactics for Working Smarter, Not Longer', '£20.59'), ('The Gutsy Girl: Escapades for Your Life of Epic Adventure', '£37.13'), ('The Electric Pencil: Drawings from Inside State Hospital No. 3', '£56.06'), ('The Death of Humanity: and the Case for Life', '£58.11'), ('The Bulletproof Diet: Lose up to a Pound a Day, Reclaim Energy and Focus, Upgrade Your Life', '£49.05'), ('The Art Forger', '£40.76'), ('The Age of Genius: The Seventeenth Century and the Birth of the Modern Mind', '£19.73'), (\"The Activist's Tao Te Ching: Ancient Advice for a Modern Revolution\", '£32.24'), ('Spark Joy: An Illustrated Master Class on the Art of Organizing and Tidying Up', '£41.83'), ('Soul Reader', '£39.58'), ('Security', '£39.25'), ('Saga, Volume 6 (Saga (Collected Editions) #6)', '£25.02'), ('Saga, Volume 5 (Saga (Collected Editions) #5)', '£51.04'), ('Reskilling America: Learning to Labor in the Twenty-First Century', '£19.83'), ('Rat Queens, Vol. 3: Demons (Rat Queens (Collected Editions) #11-15)', '£50.40')]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import time\n",
    "import random\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    def ua_random(self):\n",
    "        random_ua = ''\n",
    "        ua_file = 'agents.txt'\n",
    "        try:\n",
    "            with open(ua_file) as f:\n",
    "                lines = f.readlines()\n",
    "            if len(lines) > 0:\n",
    "                random_ua = random.choice(lines)\n",
    "                random_ua = random_ua.split('\\n')\n",
    "        except Exception as ex:\n",
    "            print('Exception in ua_random')\n",
    "            print(str(ex))\n",
    "        finally:\n",
    "            return random_ua[0] \n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        user_agent = self.ua_random()\n",
    "        #user_agent = 'Mozilla/5.0 (Windows; U; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727)'\n",
    "        headers = {'user-agent': user_agent}\n",
    "        try:\n",
    "            response = requests.get(url, headers = headers)\n",
    "            response.raise_for_status()\n",
    "            result = self.content_parser(response.content)    \n",
    "        except requests.exceptions.HTTPError as e_http:\n",
    "            result = \"Error http:\" + str(e_http)\n",
    "        except requests.exceptions.ConnectionError as e_conect:\n",
    "            result = \"Error de conexión:\" + str(e_conect)\n",
    "        except requests.exceptions.SSLError as e_ssl:\n",
    "            result = \"Error de SSL: \" + str(e_ssl)\n",
    "        except requests.exceptions.Timeout as e_time:\n",
    "            result = \"Error timeout:\" + str(e_time)\n",
    "        except requests.exceptions.TooManyRedirects as e_redi:\n",
    "            result = \"Error demasiadas redirecciones:\" + str(e_redi)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            result = \"Error Desconocido: \" + str(e)\n",
    "        \n",
    "        self.output_results(result)   \n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "            if self.sleep_interval > 0: \n",
    "                time.sleep(self.sleep_interval / 1000)\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup_contenido = BeautifulSoup(content, \"html.parser\")\n",
    "    titulos = [titulo['alt'] for titulo in soup_contenido.find_all('img')]\n",
    "    precios = [precio.text for precio in soup_contenido.find_all('p', class_=\"price_color\")]\n",
    "    libros = [ (titulos[libro], precios[libro])  for libro in range(len(titulos))]\n",
    "    \n",
    "    return libros\n",
    "\n",
    "URL_PATTERN = 'http://books.toscrape.com/catalogue/page-%d.html'\n",
    "PAGES_TO_SCRAPE = 4\n",
    "SET_INTERVAL = 1\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, SET_INTERVAL, content_parser=quotes_parser)\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 2 - Making Asynchronous Calls\n",
    "\n",
    "Implement asynchronous calls to `IronhackSpider`. You will make requests in parallel to complete your tasks faster.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A Light in the Attic', '£51.77'), ('Tipping the Velvet', '£53.74'), ('Soumission', '£50.10'), ('Sharp Objects', '£47.82'), ('Sapiens: A Brief History of Humankind', '£54.23'), ('The Requiem Red', '£22.65'), ('The Dirty Little Secrets of Getting Your Dream Job', '£33.34'), ('The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', '£17.93'), ('The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', '£22.60'), ('The Black Maria', '£52.15'), ('Starving Hearts (Triangular Trade Trilogy, #1)', '£13.99'), (\"Shakespeare's Sonnets\", '£20.66'), ('Set Me Free', '£17.46'), (\"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", '£52.29'), ('Rip it Up and Start Again', '£35.02'), ('Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991', '£57.25'), ('Olio', '£23.88'), ('Mesaerion: The Best Science Fiction Stories 1800-1849', '£37.59'), ('Libertarianism for Beginners', '£51.33'), (\"It's Only the Himalayas\", '£45.17')]\n",
      "[('In Her Wake', '£12.84'), ('How Music Works', '£37.32'), ('Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More', '£30.52'), ('Chase Me (Paris Nights #2)', '£25.27'), ('Black Dust', '£34.53'), ('Birdsong: A Story in Pictures', '£54.64'), (\"America's Cradle of Quarterbacks: Western Pennsylvania's Football Factory from Johnny Unitas to Joe Montana\", '£22.50'), ('Aladdin and His Wonderful Lamp', '£53.13'), ('Worlds Elsewhere: Journeys Around Shakespeare’s Globe', '£40.30'), ('Wall and Piece', '£44.18'), ('The Four Agreements: A Practical Guide to Personal Freedom', '£17.66'), ('The Five Love Languages: How to Express Heartfelt Commitment to Your Mate', '£31.05'), ('The Elephant Tree', '£23.82'), ('The Bear and the Piano', '£36.89'), (\"Sophie's World\", '£15.94'), ('Penny Maybe', '£33.29'), ('Maude (1883-1993):She Grew Up with the country', '£18.02'), ('In a Dark, Dark Wood', '£19.63'), ('Behind Closed Doors', '£52.22'), (\"You can't bury them all: Poems\", '£33.63')]\n",
      "[('Slow States of Collapse: Poems', '£57.31'), ('Reasons to Stay Alive', '£26.41'), ('Private Paris (Private #10)', '£47.61'), ('#HigherSelfie: Wake Up Your Life. Free Your Soul. Find Your Tribe.', '£23.11'), ('Without Borders (Wanderlove #1)', '£45.07'), ('When We Collided', '£31.77'), ('We Love You, Charlie Freeman', '£50.27'), ('Untitled Collection: Sabbath Poems 2014', '£14.27'), ('Unseen City: The Majesty of Pigeons, the Discreet Charm of Snails & Other Wonders of the Urban Wilderness', '£44.18'), ('Unicorn Tracks', '£18.78'), ('Unbound: How Eight Technologies Made Us Human, Transformed Society, and Brought Our World to the Brink', '£25.52'), ('Tsubasa: WoRLD CHRoNiCLE 2 (Tsubasa WoRLD CHRoNiCLE #2)', '£16.28'), ('Throwing Rocks at the Google Bus: How Growth Became the Enemy of Prosperity', '£31.12'), ('This One Summer', '£19.49'), ('Thirst', '£17.27'), ('The Torch Is Passed: A Harding Family Story', '£19.09'), ('The Secret of Dreadwillow Carse', '£56.13'), ('The Pioneer Woman Cooks: Dinnertime: Comfort Classics, Freezer Food, 16-Minute Meals, and Other Delicious Ways to Solve Supper!', '£56.41'), ('The Past Never Ends', '£56.50'), ('The Natural History of Us (The Fine Art of Pretending #2)', '£45.22')]\n",
      "[('The Nameless City (The Nameless City #1)', '£38.16'), ('The Murder That Never Was (Forensic Instincts #5)', '£54.11'), (\"The Most Perfect Thing: Inside (and Outside) a Bird's Egg\", '£42.96'), ('The Mindfulness and Acceptance Workbook for Anxiety: A Guide to Breaking Free from Anxiety, Phobias, and Worry Using Acceptance and Commitment Therapy', '£23.89'), ('The Life-Changing Magic of Tidying Up: The Japanese Art of Decluttering and Organizing', '£16.77'), ('The Inefficiency Assassin: Time Management Tactics for Working Smarter, Not Longer', '£20.59'), ('The Gutsy Girl: Escapades for Your Life of Epic Adventure', '£37.13'), ('The Electric Pencil: Drawings from Inside State Hospital No. 3', '£56.06'), ('The Death of Humanity: and the Case for Life', '£58.11'), ('The Bulletproof Diet: Lose up to a Pound a Day, Reclaim Energy and Focus, Upgrade Your Life', '£49.05'), ('The Art Forger', '£40.76'), ('The Age of Genius: The Seventeenth Century and the Birth of the Modern Mind', '£19.73'), (\"The Activist's Tao Te Ching: Ancient Advice for a Modern Revolution\", '£32.24'), ('Spark Joy: An Illustrated Master Class on the Art of Organizing and Tidying Up', '£41.83'), ('Soul Reader', '£39.58'), ('Security', '£39.25'), ('Saga, Volume 6 (Saga (Collected Editions) #6)', '£25.02'), ('Saga, Volume 5 (Saga (Collected Editions) #5)', '£51.04'), ('Reskilling America: Learning to Labor in the Twenty-First Century', '£19.83'), ('Rat Queens, Vol. 3: Demons (Rat Queens (Collected Editions) #11-15)', '£50.40')]\n",
      "[('Princess Jellyfish 2-in-1 Omnibus, Vol. 01 (Princess Jellyfish 2-in-1 Omnibus #1)', '£13.61'), ('Princess Between Worlds (Wide-Awake Princess #5)', '£13.34'), ('Pop Gun War, Volume 1: Gift', '£18.97'), ('Political Suicide: Missteps, Peccadilloes, Bad Calls, Backroom Hijinx, Sordid Pasts, Rotten Breaks, and Just Plain Dumb Mistakes in the Annals of American Politics', '£36.28'), ('Patience', '£10.16'), ('Outcast, Vol. 1: A Darkness Surrounds Him (Outcast #1)', '£15.44'), ('orange: The Complete Collection 1 (orange: The Complete Collection #1)', '£48.41'), ('Online Marketing for Busy Authors: A Step-By-Step Guide', '£46.35'), ('On a Midnight Clear', '£14.07'), ('Obsidian (Lux #1)', '£14.86'), ('My Paris Kitchen: Recipes and Stories', '£33.37'), ('Masks and Shadows', '£56.40'), ('Mama Tried: Traditional Italian Cooking for the Screwed, Crude, Vegan, and Tattooed', '£14.02'), ('Lumberjanes, Vol. 2: Friendship to the Max (Lumberjanes #5-8)', '£46.91'), ('Lumberjanes, Vol. 1: Beware the Kitten Holy (Lumberjanes #1-4)', '£45.61'), ('Lumberjanes Vol. 3: A Terrible Plan (Lumberjanes #9-12)', '£19.92'), ('Layered: Baking, Building, and Styling Spectacular Cakes', '£40.11'), ('Judo: Seven Steps to Black Belt (an Introductory Guide for Beginners)', '£53.90'), ('Join', '£35.67'), ('In the Country We Love: My Family Divided', '£22.00')]\n",
      "[('Immunity: How Elie Metchnikoff Changed the Course of Modern Medicine', '£57.36'), ('I Hate Fairyland, Vol. 1: Madly Ever After (I Hate Fairyland (Compilations) #1-5)', '£29.17'), ('I am a Hero Omnibus Volume 1', '£54.63'), ('How to Be Miserable: 40 Strategies You Already Use', '£46.03'), ('Her Backup Boyfriend (The Sorensen Family #1)', '£33.97'), ('Giant Days, Vol. 2 (Giant Days #5-8)', '£22.11'), ('Forever and Forever: The Courtship of Henry Longfellow and Fanny Appleton', '£29.69'), ('First and First (Five Boroughs #3)', '£15.97'), ('Fifty Shades Darker (Fifty Shades #2)', '£21.96'), ('Everydata: The Misinformation Hidden in the Little Data You Consume Every Day', '£54.35'), (\"Don't Be a Jerk: And Other Practical Advice from Dogen, Japan's Greatest Zen Master\", '£37.97'), ('Danganronpa Volume 1', '£51.99'), ('Crown of Midnight (Throne of Glass #2)', '£43.29'), ('Codename Baboushka, Volume 1: The Conclave of Death', '£36.72'), ('Camp Midnight', '£17.08'), ('Call the Nurse: True Stories of a Country Nurse on a Scottish Isle', '£29.14'), ('Burning', '£28.81'), ('Bossypants', '£49.46'), ('Bitch Planet, Vol. 1: Extraordinary Machine (Bitch Planet (Collected Editions))', '£37.92'), ('Avatar: The Last Airbender: Smoke and Shadow, Part 3 (Smoke and Shadow #3)', '£28.09')]\n",
      "[('Algorithms to Live By: The Computer Science of Human Decisions', '£30.81'), ('A World of Flavor: Your Gluten Free Passport', '£42.95'), ('A Piece of Sky, a Grain of Rice: A Memoir in Four Meditations', '£56.76'), ('A Murder in Time', '£16.64'), ('A Flight of Arrows (The Pathfinders #2)', '£55.53'), ('A Fierce and Subtle Poison', '£28.13'), ('A Court of Thorns and Roses (A Court of Thorns and Roses #1)', '£52.37'), ('(Un)Qualified: How God Uses Broken People to Do Big Things', '£54.00'), ('You Are What You Love: The Spiritual Power of Habit', '£21.87'), (\"William Shakespeare's Star Wars: Verily, A New Hope (William Shakespeare's Star Wars #4)\", '£43.30'), ('Tuesday Nights in 1980', '£21.04'), ('Tracing Numbers on a Train', '£41.60'), ('Throne of Glass (Throne of Glass #1)', '£35.07'), ('Thomas Jefferson and the Tripoli Pirates: The Forgotten War That Changed American History', '£59.64'), ('Thirteen Reasons Why', '£52.72'), ('The White Cat and the Monk: A Retelling of the Poem “Pangur Bán”', '£58.08'), ('The Wedding Dress', '£24.12'), ('The Vacationers', '£42.15'), ('The Third Wave: An Entrepreneur’s Vision of the Future', '£12.61'), ('The Stranger', '£17.44')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The Shadow Hero (The Shadow Hero)', '£33.14'), ('The Secret (The Secret #1)', '£27.37'), ('The Regional Office Is Under Attack!', '£51.36'), ('The Psychopath Test: A Journey Through the Madness Industry', '£36.00'), ('The Project', '£10.65'), ('The Power of Now: A Guide to Spiritual Enlightenment', '£43.54'), (\"The Omnivore's Dilemma: A Natural History of Four Meals\", '£38.21'), ('The Nerdy Nummies Cookbook: Sweet Treats for the Geek in All of Us', '£37.34'), ('The Murder of Roger Ackroyd (Hercule Poirot #4)', '£44.10'), ('The Mistake (Off-Campus #2)', '£43.29'), (\"The Matchmaker's Playbook (Wingmen Inc. #1)\", '£55.85'), ('The Love and Lemons Cookbook: An Apple-to-Zucchini Celebration of Impromptu Cooking', '£37.60'), ('The Long Shadow of Small Ghosts: Murder and Memory in an American City', '£10.97'), ('The Kite Runner', '£41.82'), ('The House by the Lake', '£36.95'), ('The Glittering Court (The Glittering Court #1)', '£44.28'), ('The Girl on the Train', '£55.02'), ('The Genius of Birds', '£17.24'), ('The Emerald Mystery', '£23.15'), ('The Cookies & Cups Cookbook: 125+ sweet & savory recipes reminding you to Always Eat Dessert First', '£41.25')]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import random\n",
    "import asyncio\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    def ua_random(self):\n",
    "        random_ua = ''\n",
    "        ua_file = 'agents.txt'\n",
    "        try:\n",
    "            with open(ua_file) as f:\n",
    "                lines = f.readlines()\n",
    "            if len(lines) > 0:\n",
    "                random_ua = random.choice(lines)\n",
    "                random_ua = random_ua.split('\\n')\n",
    "        except Exception as ex:\n",
    "            print('Exception in ua_random')\n",
    "            print(str(ex))\n",
    "        finally:\n",
    "            return random_ua[0] \n",
    "        \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    async def scrape_url(self, url):\n",
    "        user_agent = self.ua_random()\n",
    "        headers = {'user-agent': user_agent}\n",
    "        \n",
    "        loop = asyncio.get_event_loop()\n",
    "        future = loop.run_in_executor(None, requests.get, url, headers)\n",
    "        response = await future\n",
    "\n",
    "        try:\n",
    "            #response = requests.get(url, headers = headers)\n",
    "            response.raise_for_status()\n",
    "            result = self.content_parser(response.content)    \n",
    "        except requests.exceptions.HTTPError as e_http:\n",
    "            result = \"Error http:\" + str(e_http)\n",
    "        except requests.exceptions.ConnectionError as e_conect:\n",
    "            result = \"Error de conexión:\" + str(e_conect)\n",
    "        except requests.exceptions.SSLError as e_ssl:\n",
    "            result = \"Error de SSL: \" + str(e_ssl)\n",
    "        except requests.exceptions.Timeout as e_time:\n",
    "            result = \"Error timeout:\" + str(e_time)\n",
    "        except requests.exceptions.TooManyRedirects as e_redi:\n",
    "            result = \"Error demasiadas redirecciones:\" + str(e_redi)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            result = \"Error Desconocido: \" + str(e)\n",
    "        \n",
    "        self.output_results(result)   \n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\" \n",
    "\n",
    "    async def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            await self.scrape_url(self.url_pattern % i)\n",
    "            if self.sleep_interval > 0: \n",
    "                time.sleep(self.sleep_interval / 1000)        \n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup_contenido = BeautifulSoup(content, \"html.parser\")\n",
    "    titulos = [titulo['alt'] for titulo in soup_contenido.find_all('img')]\n",
    "    precios = [precio.text for precio in soup_contenido.find_all('p', class_=\"price_color\")]\n",
    "    libros = [ (titulos[libro], precios[libro])  for libro in range(len(titulos))]\n",
    "    \n",
    "    return libros\n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://books.toscrape.com/catalogue/page-%d.html'\n",
    "PAGES_TO_SCRAPE = 8\n",
    "SET_INTERVAL = 2\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, SET_INTERVAL, content_parser=quotes_parser)\n",
    "\n",
    "await my_spider.kickstart() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
